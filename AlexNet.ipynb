{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "97eadc29",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, MaxPool2D, Dense, Flatten\n",
    "import pickle\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "12f8cbcc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Building AlexNet\n",
    "\n",
    "class AlexNet():\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.model = Sequential()\n",
    "        self.model.add(Conv2D(96, input_shape=(224, 224, 3), kernel_size=11, activation=\"relu\"))\n",
    "        self.model.add(MaxPool2D((3,3)))\n",
    "        self.model.add(Conv2D(256, kernel_size=5, activation=\"relu\"))\n",
    "        self.model.add(MaxPool2D((3,3)))\n",
    "        self.model.add(Conv2D(384, kernel_size=3, activation=\"relu\"))\n",
    "        self.model.add(MaxPool2D((3,3)))\n",
    "        self.model.add(Conv2D(256, kernel_size=3, activation=\"relu\"))\n",
    "        self.model.add(MaxPool2D((3,3)))\n",
    "        self.model.add(Flatten())\n",
    "        self.model.add(Dense(4096, activation=\"leaky_relu\"))\n",
    "        self.model.add(Dense(4096, activation=\"linear\"))\n",
    "        self.model.add(Dense(32))\n",
    "        self.model.compile(optimizer=tf.keras.optimizers.SGD(learning_rate=0.000001, momentum=0.0, nesterov=False, name='SGD'), loss=\"mean_squared_error\", metrics=\"accuracy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5bf036e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = AlexNet()\n",
    "#model.model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "06dd0bbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "KEYPOINT_DICT = {\n",
    "    'nose': 0,\n",
    "    'left_eye': 1,\n",
    "    'right_eye': 2,\n",
    "    'left_ear': 3,\n",
    "    'right_ear': 4,\n",
    "    'left_shoulder': 5,\n",
    "    'right_shoulder': 6,\n",
    "    'left_elbow': 7,\n",
    "    'right_elbow': 8,\n",
    "    'left_wrist': 9,\n",
    "    'right_wrist': 10,\n",
    "    'left_hip': 11,\n",
    "    'right_hip': 12,\n",
    "    'left_knee': 13,\n",
    "    'right_knee': 14,\n",
    "    'left_ankle': 15,\n",
    "    'right_ankle': 16\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8d7aaef5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create custom dataset\n",
    "\n",
    "with open('data_annote', 'rb') as f:\n",
    "    DATA = pickle.load(f)\n",
    "    \n",
    "file_paths = [idx[0] for idx in DATA]\n",
    "joint_keyframes = np.asarray([np.asarray(idx[1]).flatten() for idx in DATA])\n",
    "\n",
    "ds_train = tf.data.Dataset.from_tensor_slices((file_paths, joint_keyframes))\n",
    "\n",
    "def read_image(image_file, joint_keyframes):\n",
    "    image = tf.io.read_file(image_file)\n",
    "    image = tf.image.decode_image(image, channels=3, dtype=tf.float32)\n",
    "    image.set_shape([640, 640, 3])\n",
    "    image = tf.image.resize(image, [224, 224])\n",
    "    return image, joint_keyframes\n",
    "\n",
    "def image_resize(image_file, joint_keyframes):\n",
    "    image = tf.io.read_file(image_file)\n",
    "    image =  tf.image.decode_jpeg(image, channels=3, dtype=tf.float32) \n",
    "    image_file = tf.image.resize(image, [224,224,3])\n",
    "    \n",
    "    return image_file, joint_keyframes\n",
    "\n",
    "\n",
    "ds_train = ds_train.map(read_image).batch(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07cc3765",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "2134/7488 [=======>......................] - ETA: 44:48 - loss: 344034.5000 - accuracy: 0.0220"
     ]
    }
   ],
   "source": [
    "model.model.fit(ds_train, epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "709052ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "joint_keyframes[100].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc74f2cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5afead81",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"train.json\") as f:\n",
    "    jsonData = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e04b4f4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "cc = 0\n",
    "dataData = []\n",
    "for i in jsonData:\n",
    "    if 0 in i['joints_vis']:\n",
    "        continue\n",
    "    else:\n",
    "        dataData.append(('images/' + i['image'], i['joints'])) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e087b6e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('data_annote', 'wb') as file:\n",
    "    pickle.dump(dataData, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d5fc05b",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataData"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f58e01f9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
